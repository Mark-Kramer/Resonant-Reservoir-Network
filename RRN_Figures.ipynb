{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0533faf9-6396-4d1e-b544-c76668fd6af2",
   "metadata": {},
   "source": [
    "# 0. Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d2040-b037-4e2d-ae10-d0f6bf1202f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Optuna Results and Report it.\n",
    "\n",
    "import optuna\n",
    "save_name = \"sqlite:///dat/sim_optuna_results_2025-05-15.db\"\n",
    "study     = optuna.load_study(study_name=\"sim_optuna\", storage=save_name)\n",
    "best      = study.best_params\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"\\nBest accuracy:\", study.best_value)\n",
    "\n",
    "print(f\"\\nfstep:                {best[\"fstep\"]}\")\n",
    "print(f\"sigma:                {best[\"sigma\"]}\")\n",
    "print(f\"sparsity:             {best[\"sparsity\"]}\")\n",
    "print(f\"spectral_radius:      {best[\"spectral_radius\"]}\")\n",
    "print(f\"base_geometric_ratio: {best[\"base_geometric_ratio\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9e207-8b3d-4aaf-808c-e85829af1809",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Simulated neural rhythmsÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f35c04-4bd9-4a9b-a248-f3d2de1c1b3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1A): Example traces of simulated neural events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac872b-9bee-484f-8600-ea142af9ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from ReservoirNetwork_utils import plot_example_simulated_traces\n",
    "\n",
    "load_name      = \"dat/SIM_accuracy_results_reservoir_2025-05-15\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "X_train = results['X_train']\n",
    "y_train = results['y_train']\n",
    "\n",
    "f = plot_example_simulated_traces(X_train, y_train)\n",
    "#f.savefig(\"./PDFs/Figure-1A.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a8cec-3f74-42c4-ab0b-97e21ab8ef16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1B): Example spectra of reservoir nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0097b-cb75-48d2-9305-cd831df3b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReservoirNetwork import ReservoirNetwork\n",
    "\n",
    "res_net         = ReservoirNetwork(Fs=1000)\n",
    "history_weights, frange = res_net.generate_history_weights()\n",
    "w_t_minus_1     = history_weights[\"w_t_minus_1\"]\n",
    "w_t_minus_2     = history_weights[\"w_t_minus_2\"]\n",
    "\n",
    "# Use the history weights to plot the spectrum of each node.\n",
    "from ReservoirNetwork_utils import plot_analytic_spectrum\n",
    "f = plot_analytic_spectrum(w_t_minus_1, w_t_minus_2, node_step=25)\n",
    "#f.savefig(\"./PDFs/Figure-1B.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a5332-f0ef-401f-b240-d766f8601732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1C): Example traces of noise-driven reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c3fcd-6ef4-4860-8417-1b9aabb23071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from   ReservoirNetwork import ReservoirNetwork\n",
    "\n",
    "# Get the state dynamics with zero input.\n",
    "res_net                    = ReservoirNetwork(Fs=1000)\n",
    "history_weights, frange    = res_net.generate_history_weights()\n",
    "input_time_series          = np.zeros(1000)\n",
    "states, amplitudes, phases = res_net.collect_states(input_time_series)\n",
    "\n",
    "from ReservoirNetwork_utils import plot_state_dynamics\n",
    "f = plot_state_dynamics(states, node_step=25, plot_spacing=0.2, frange=frange)\n",
    "#f.savefig(\"./PDFs/Figure-1C.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e37b4b-4987-474b-b6b2-af2d4c063767",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1D): Average confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddd90f-ae88-431b-bda7-cf5f7f762eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "load_name      = \"dat/SIM_accuracy_results_reservoir_2025-05-15\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy       = results['accuracy']\n",
    "confuse_matrix = results['confuse_matrix']\n",
    "X_test         = results['X_test']\n",
    "K              = X_test.shape[0]/4\n",
    "\n",
    "# Print accuracy metrics\n",
    "print(\"Accuracy\")\n",
    "print(f\"Mean: {np.mean(accuracy):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy):.3f}\")\n",
    "\n",
    "# Compute the average confusion matrix over all k iterations\n",
    "avg_confuse_matrix = np.mean(confuse_matrix, axis=0)/K\n",
    "\n",
    "# Define class labels (adjust if needed)\n",
    "classes = [\"Spike Ripple\", \"Spike\", \"Ripple\", \"Background\"]\n",
    "\n",
    "f = plt.figure(figsize=(5, 5))\n",
    "plt.imshow(avg_confuse_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations to each cell in the matrix\n",
    "thresh = avg_confuse_matrix.max() / 2.\n",
    "for i in range(avg_confuse_matrix.shape[0]):\n",
    "    for j in range(avg_confuse_matrix.shape[1]):\n",
    "        plt.text(j, i, f\"{avg_confuse_matrix[i, j]:.2f}\", horizontalalignment=\"center\",\n",
    "                 color=\"white\" if avg_confuse_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#f.savefig(\"./PDFs/Figure-1D.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff367c9-81cc-4f39-89ac-dd9cba43a4ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1E): Results for different step sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41459941-4878-45a0-a615-5165c89ef1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Construct list of file names.\n",
    "load_names = [\"dat/SIM_accuracy_results_reservoir_2025-05-15\"] + [\n",
    "    f\"dat/SIM_accuracy_results_fstep_{i}_date_2025-05-16\" for i in range(2, 21)\n",
    "]\n",
    "\n",
    "num_files = len(load_names)\n",
    "mean_accuracy = np.zeros(num_files)\n",
    "std_accuracy  = np.zeros(num_files)\n",
    "n_nodes       = np.zeros(num_files)\n",
    "f_step        = np.zeros(num_files)\n",
    "\n",
    "# Loop over each file, load the results, and compute accuracy stats.\n",
    "for k, load_name in enumerate(load_names):\n",
    "    with open(load_name + '.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    accuracy = results['accuracy']\n",
    "    mean_accuracy[k] = np.mean(accuracy)\n",
    "    std_accuracy[k]  = np.std(accuracy)\n",
    "    n_nodes[k]       = np.shape(results['X_train_features'])[1]\n",
    "    f_step[k]        = results['res_net'].fstep\n",
    "\n",
    "# Define x positions\n",
    "x_positions = np.arange(1, num_files + 1)\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.errorbar(\n",
    "    x_positions, \n",
    "    mean_accuracy, \n",
    "    yerr=std_accuracy, \n",
    "    fmt='o', \n",
    "    capsize=5, \n",
    "    markersize=8, \n",
    "    color='blue', \n",
    "    ecolor='black', \n",
    "    linestyle='None'\n",
    ")\n",
    "\n",
    "# Bottom x-axis labels (frequency)\n",
    "bottom_labels = [f\"{int(f)} Hz\" for f in f_step]\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(bottom_labels, rotation=45)\n",
    "\n",
    "# Add top x-axis with node count labels\n",
    "ax_top = ax.twiny()\n",
    "ax_top.set_xticks(x_positions)\n",
    "top_labels = [f\"n={int(n)}\" for n in n_nodes]\n",
    "ax_top.set_xticklabels(top_labels, rotation=45)\n",
    "ax_top.set_xlim(ax.get_xlim())\n",
    "\n",
    "# Label and formatting\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig(\"./PDFs/Figure-1E.pdf\", bbox_inches='tight')\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(np.transpose([x_positions, mean_accuracy, std_accuracy]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d14281-5a66-4fa9-b9ce-c01eec28822d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Print out) Compare to alternative classification via power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d047f9e-ad32-4d59-9c28-60c51b27aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "load_name      = \"dat/SIM_accuracy_results_reservoir_2025-05-15\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy_RRN       = results['accuracy']\n",
    "correct_counts_RRN = results['correct_counts']\n",
    "X_test             = results['X_test']\n",
    "K                  = X_test.shape[0]/4\n",
    "\n",
    "load_name      = \"dat/SIM_accuracy_results_fft_power_2025-05-15\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy_pow       = results['accuracy']\n",
    "correct_counts_pow = results['correct_counts']\n",
    "\n",
    "\n",
    "# Print accuracy metrics\n",
    "print(\"Accuracy RRN\")\n",
    "print(f\"Mean: {np.mean(accuracy_RRN):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy_RRN):.3f}\")\n",
    "print(\"Count :\", np.size(accuracy_RRN))\n",
    "\n",
    "print(\"\\nAccuracy Power\")\n",
    "print(f\"Mean: {np.mean(accuracy_pow):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy_pow):.3f}\")\n",
    "print(\"Count :\", np.size(accuracy_pow))\n",
    "\n",
    "# Two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(accuracy_RRN, accuracy_pow)\n",
    "print(\"\\nAccuracy RRN vs Power\")\n",
    "print(f\"T-statistic:, {t_statistic:.1f}\")\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee236b7e-5638-4cbe-92fa-8ff9e4b83aba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 1F): Plot example average responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5109c-8ca6-4783-b2bf-788de0fb00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from ReservoirNetwork       import ReservoirNetwork\n",
    "from ReservoirNetwork_utils import plot_scaled_reservoir_responses_by_label\n",
    "\n",
    "# Get the state dynamics with zero input.\n",
    "res_net = ReservoirNetwork(Fs=1000)\n",
    "\n",
    "load_name      = \"dat/SIM_accuracy_results_reservoir_2025-05-15\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "X_test_features = results['X_test_features']\n",
    "y_test = results['y_test']\n",
    "scaler = results['scaler']\n",
    "res_net = results['res_net']\n",
    "\n",
    "fig, ax = plot_scaled_reservoir_responses_by_label(X_test_features, y_test, res_net, scaler)\n",
    "#fig.savefig(\"./PDFs/Figure-1F.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c847c-42fc-4bc3-8523-fcaecd59fd64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# 2. In vivo neural rhythms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f793e61-b3a6-439d-a8c8-3c5fc463e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "load_name      = \"dat/INVIVO_accuracy_results_2025-05-17\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy    = results['accuracy']\n",
    "sensitivity = results['sensitivity']\n",
    "specificity = results['specificity']\n",
    "PPV         = results['PPV']\n",
    "NPV         = results['NPV']\n",
    "\n",
    "# Print classification metrics\n",
    "\n",
    "print(\"\\nSensitivity\")\n",
    "print(f\"Mean: {np.mean(sensitivity):.3f}\")\n",
    "print(f\"STD : {np.std(sensitivity):.3f}\")\n",
    "\n",
    "print(\"\\nSpecificity\")\n",
    "print(f\"Mean: {np.mean(specificity):.3f}\")\n",
    "print(f\"STD : {np.std(specificity):.3f}\")\n",
    "\n",
    "print(\"\\nPPV\")\n",
    "print(f\"Mean: {np.mean(PPV):.3f}\")\n",
    "print(f\"STD : {np.std(PPV):.3f}\")\n",
    "\n",
    "print(\"\\nNPV\")\n",
    "print(f\"Mean: {np.mean(NPV):.3f}\")\n",
    "print(f\"STD : {np.std(NPV):.3f}\")\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "print(f\"Mean: {np.mean(accuracy):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501a15d-d7e2-4011-aefb-e540d54420f4",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eead57b-86e9-4d2f-b185-3d47c8b17232",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 2A): Counts and plot of example scanline traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90b216-d031-4c43-ae69-580bcdd3dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Load the MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype(np.float32)  # Flatten images from (60000, 28, 28) to (60000, 784)\n",
    "X_train /= 255.0                                          # Normalize pixel values to range [0, 1]\n",
    "\n",
    "# Count the labels for training and testing subsets\n",
    "train_counts = dict(Counter(y_train))\n",
    "test_counts = dict(Counter(y_test))\n",
    "\n",
    "# Print the table header\n",
    "print(\"{:<10}{:<20}{:<20}\".format(\"Digit\", \"Training Count\", \"Testing Count\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print counts for each digit from 0 to 9\n",
    "for digit in range(10):\n",
    "    train_count = train_counts.get(digit, 0)\n",
    "    test_count = test_counts.get(digit, 0)\n",
    "    print(\"{:<10},{:<20},{:<20}\".format(digit, train_count, test_count))\n",
    "\n",
    "# Compute totals for training and testing\n",
    "total_train = sum(train_counts.values())\n",
    "total_test = sum(test_counts.values())\n",
    "\n",
    "print(\"{:<10},{:<20},{:<20}\".format(\"Total\", total_train, total_test))\n",
    "\n",
    "# Indices to plot.\n",
    "indices = [1, 3, 5]\n",
    "\n",
    "f, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 5))\n",
    "for i, k in enumerate(indices):\n",
    "\n",
    "    # Plot the image\n",
    "    axes[i, 0].imshow(X_train[k].reshape(28,28), cmap='gray_r')\n",
    "    axes[i, 0].axis('off')  # Remove x and y axes from the image.\n",
    "    \n",
    "    # Plot the line\n",
    "    axes[i, 1].plot(X_train[k], 'k')\n",
    "    axes[i, 1].set_xlim([0, 784])\n",
    "    axes[i, 1].set_ylim([0, 1])\n",
    "    axes[i, 1].spines['top'].set_visible(False)\n",
    "    axes[i, 1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "#f.savefig(\"./PDFs/Figure-2A.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58171010-5eea-4ccc-a016-ab7d239c9198",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 2B): Average confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089c560-6ab1-42a5-8140-25eb001cc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "load_name      = \"dat/MNIST_accuracy_results_2025-05-20\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy         = results['accuracy']\n",
    "confuse_matrix   = results['confuse_matrix']\n",
    "X_train_features = results['X_train_features']\n",
    "\n",
    "# Number of features in classification\n",
    "print(f\"Number of features: {np.shape(X_train_features)[1]}\")\n",
    "\n",
    "# Print accuracy metrics with three decimal places\n",
    "print(\"Accuracy\")\n",
    "print(f\"Mean: {np.mean(accuracy):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy):.3f}\")\n",
    "\n",
    "# Compute the sum for each row in each matrix.\n",
    "row_sums = confuse_matrix.sum(axis=2, keepdims=True)\n",
    "\n",
    "# Normalize each row by dividing by its row sum.\n",
    "normalized_confuse_matrix = confuse_matrix / row_sums\n",
    "\n",
    "# Compute the average confusion matrix over all iterations\n",
    "avg_confuse_matrix = np.mean(normalized_confuse_matrix, axis=0)\n",
    "\n",
    "# Define class labels (adjust if needed)\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "f = plt.figure(figsize=(8, 6))\n",
    "plt.imshow(avg_confuse_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Average Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations to each cell in the matrix\n",
    "thresh = avg_confuse_matrix.max() / 2.\n",
    "for i in range(avg_confuse_matrix.shape[0]):\n",
    "    for j in range(avg_confuse_matrix.shape[1]):\n",
    "        plt.text(j, i, f\"{avg_confuse_matrix[i, j]:.2f}\", horizontalalignment=\"center\",\n",
    "                 color=\"white\" if avg_confuse_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#f.savefig(\"./PDFs/Figure-2B.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55cb234-6aac-4a76-85e1-24fb24b9e932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Table 3): Accuracy versus step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13a974-6f8c-490a-a63e-a10376e781a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Construct list of file names.\n",
    "load_names = [\"dat/MNIST_accuracy_results_2025-05-20\"] + [\n",
    "    f\"dat/MNIST_accuracy_results_fstep_{i}_date_2025-05-20\" for i in range(2, 11)\n",
    "]\n",
    "\n",
    "num_files = len(load_names)\n",
    "mean_accuracy = np.zeros(num_files)\n",
    "std_accuracy  = np.zeros(num_files)\n",
    "n_nodes       = np.zeros(num_files)\n",
    "f_step        = np.zeros(num_files)\n",
    "\n",
    "# Loop over each file, load the results, and compute accuracy stats.\n",
    "for k, load_name in enumerate(load_names):\n",
    "    with open(load_name + '.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    accuracy = results['accuracy']\n",
    "    mean_accuracy[k] = np.mean(accuracy)\n",
    "    std_accuracy[k]  = np.std(accuracy)\n",
    "    n_nodes[k]       = np.shape(results['X_train_features'])[1]\n",
    "    f_step[k]        = results['res_net'].fstep\n",
    "\n",
    "# Define x positions\n",
    "x_positions = np.arange(1, num_files + 1)\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.errorbar(\n",
    "    x_positions, \n",
    "    mean_accuracy, \n",
    "    yerr=std_accuracy, \n",
    "    fmt='o', \n",
    "    capsize=5, \n",
    "    markersize=8, \n",
    "    color='blue', \n",
    "    ecolor='black', \n",
    "    linestyle='None'\n",
    ")\n",
    "\n",
    "# Bottom x-axis labels (frequency)\n",
    "bottom_labels = [f\"{int(f)} Hz\" for f in f_step]\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(bottom_labels, rotation=45)\n",
    "\n",
    "# Add top x-axis with node count labels\n",
    "ax_top = ax.twiny()\n",
    "ax_top.set_xticks(x_positions)\n",
    "top_labels = [f\"n={int(n)}\" for n in n_nodes]\n",
    "ax_top.set_xticklabels(top_labels, rotation=45)\n",
    "ax_top.set_xlim(ax.get_xlim())\n",
    "\n",
    "# Label and formatting\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig(\"./PDFs/Figure-1E.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Print out results.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(np.transpose([x_positions, mean_accuracy, std_accuracy]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d6ad2-9ae2-4e48-b44b-ef5a44991ae8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 2C): Example average responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea19c9-1bed-4269-a506-deffd9936c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it respond to the test set?\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "load_name      = \"dat/MNIST_accuracy_results_2025-05-20\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "X_test_features  = results['X_test_features']\n",
    "y_test           = results['y_test']\n",
    "res_net          = results['res_net']\n",
    "clf              = results['clf']\n",
    "scaler           = clf.named_steps['scaler']\n",
    "\n",
    "# Gather counts of each digit for printout\n",
    "counts = []\n",
    "print(f\"{'Digit':<10}{'Count':<20}\")\n",
    "for digit in range(10):\n",
    "    cnt = np.sum(y_test == digit)\n",
    "    counts.append(cnt)\n",
    "    print(f\"{digit:<10}{cnt:<20}\")\n",
    "\n",
    "# Compute mean and std over digits\n",
    "mean_count = np.mean(counts)\n",
    "std_count  = np.std(counts)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(f\"{'Mean count ':<10}{mean_count:.3f}\")\n",
    "print(f\"{'Std dev ':<10}{std_count:.3f}\")\n",
    "\n",
    "from ReservoirNetwork_utils import plot_scaled_reservoir_responses_by_label\n",
    "fig, ax = plot_scaled_reservoir_responses_by_label(X_test_features, y_test, res_net, scaler)\n",
    "#fig.savefig(\"./PDFs/Figure-2C.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85237d-f210-44e6-8be7-225dda13d289",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Speech Commands Dataset (SCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f07bd-2c58-4414-8780-ca2d4c06fee8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 3A): Average confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353cb57-10a5-4866-a872-b5b9e6ae3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "load_name      = \"dat/SDDS_accuracy_results_2025-05-29\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "accuracy       = results['accuracy']\n",
    "confuse_matrix = results['confuse_matrix']\n",
    "\n",
    "# Print accuracy metrics with three decimal places\n",
    "print(\"Accuracy\")\n",
    "print(f\"Mean: {np.mean(accuracy):.3f}\")\n",
    "print(f\"STD : {np.std(accuracy):.3f}\")\n",
    "\n",
    "# Compute the sum for each row in each matrix.\n",
    "row_sums = confuse_matrix.sum(axis=2, keepdims=True)\n",
    "\n",
    "# Normalize each row by dividing by its row sum.\n",
    "normalized_confuse_matrix = confuse_matrix / row_sums\n",
    "\n",
    "# Compute the average confusion matrix over all iterations\n",
    "avg_confuse_matrix = np.mean(normalized_confuse_matrix, axis=0)\n",
    "\n",
    "# Define class labels\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "f = plt.figure(figsize=(8, 6))\n",
    "plt.imshow(avg_confuse_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Average Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations to each cell in the matrix\n",
    "thresh = avg_confuse_matrix.max() / 2.\n",
    "for i in range(avg_confuse_matrix.shape[0]):\n",
    "    for j in range(avg_confuse_matrix.shape[1]):\n",
    "        plt.text(j, i, f\"{avg_confuse_matrix[i, j]:.2f}\", horizontalalignment=\"center\",\n",
    "                 color=\"white\" if avg_confuse_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#f.savefig(\"./PDFs/Figure-3A.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a57fa8-a3bf-4d25-99eb-68ac71c9d085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (Figure 3B): Example average response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5459a4-7199-4fe7-8ba9-e089649168d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "load_name      = \"dat/SDDS_accuracy_results_2025-05-29\"\n",
    "with open(load_name + '.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "X_test_features  = results['X_test_features']\n",
    "y_test           = results['y_test']\n",
    "res_net          = results['res_net']\n",
    "scaler           = results['scaler']\n",
    "\n",
    "# Gather counts in a list so we can compute stats\n",
    "counts = []\n",
    "print(f\"{'Digit':<10}{'Count':<20}\")\n",
    "for digit in range(10):\n",
    "    cnt = np.sum(y_test == digit)\n",
    "    counts.append(cnt)\n",
    "    print(f\"{digit:<10}{cnt:<20}\")\n",
    "\n",
    "print(f\"{'Mean '}{np.mean(counts):.1f}{', STD '}{np.std(counts):.1f}\")\n",
    "\n",
    "from ReservoirNetwork_utils import plot_scaled_reservoir_responses_by_label\n",
    "fig, ax = plot_scaled_reservoir_responses_by_label(X_test_features, y_test, res_net, scaler)\n",
    "#fig.savefig(\"./PDFs/Figure-3B.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
